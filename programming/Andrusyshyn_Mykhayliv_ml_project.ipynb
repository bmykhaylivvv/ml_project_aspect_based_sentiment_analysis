{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CORENLP_HOME=./stanford-corenlp-4.5.4\n"
     ]
    }
   ],
   "source": [
    "%env CORENLP_HOME=./stanford-corenlp-4.5.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import stanza\n",
    "# Import client module\n",
    "from stanza.server import CoreNLPClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "import nltk\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.23.5'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.version.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-25 20:37:58.375871: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import one_hot, Tokenizer\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Activation, Dropout, Dense\n",
    "from keras.layers import Flatten, GlobalMaxPooling1D, Embedding, Conv1D, LSTM, MaxPooling1D\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   s.no  age   division_name department_name class_name  clothing_id  \\\n",
      "0     0   40         General         Bottoms      Jeans         1028   \n",
      "1     1   62  General Petite            Tops    Blouses          850   \n",
      "2     2   47  General Petite         Bottoms     Skirts          993   \n",
      "3     3   45  General Petite         Bottoms      Pants         1068   \n",
      "4     4   37       Initmates        Intimate       Swim           24   \n",
      "\n",
      "                    title                                        review_text  \\\n",
      "0    Amazing fit and wash  Like other reviewers i was hesitant to spend t...   \n",
      "1      Lovely and unique!  As is true of a bunch of the fall clothing pho...   \n",
      "2                     Meh  I so wanted this skirt to work, love the desig...   \n",
      "3                     Wow  Love love this! i was hesitant to buy this at ...   \n",
      "4  Great for bigger busts  I absolutely love the retro look of this swims...   \n",
      "\n",
      "   alike_feedback_count  rating  recommend_index   \n",
      "0                     0       5                 1  \n",
      "1                    12       5                 1  \n",
      "2                     3       1                 0  \n",
      "3                     0       5                 1  \n",
      "4                     0       5                 1  \n",
      "(23486, 2)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('./data/women_dresses_reviews_dataset.csv')\n",
    "\n",
    "print(df.head())\n",
    "\n",
    "df = df[['review_text', 'rating']]\n",
    "\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_text</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Like other reviewers i was hesitant to spend t...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>As is true of a bunch of the fall clothing pho...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I so wanted this skirt to work, love the desig...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Love love this! i was hesitant to buy this at ...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I absolutely love the retro look of this swims...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         review_text  rating\n",
       "0  Like other reviewers i was hesitant to spend t...       5\n",
       "1  As is true of a bunch of the fall clothing pho...       5\n",
       "2  I so wanted this skirt to work, love the desig...       1\n",
       "3  Love love this! i was hesitant to buy this at ...       5\n",
       "4  I absolutely love the retro look of this swims...       5"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = df['rating'].value_counts().sort_index().plot(kind='bar', title='Count of Reviews by Stars', figsize=(10, 5))\n",
    "ax.set_xlabel('Review Stars')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I tried this on in my usual size and it was tight through the chest because of the lining. i would have preferred to wear a cami beneath and then it may have worked. the color and pattern are gorgeous, the fabric feels a bit weird, kind of dry and rough? would have liked to see this in a longer length, and more tapered. it is an absolute pregnant top. so sad its so pretty!\n"
     ]
    }
   ],
   "source": [
    "example = df['review_text'][100]\n",
    "\n",
    "print(example)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22641, 2)\n"
     ]
    }
   ],
   "source": [
    "# Remove reviews with nan in review_text column\n",
    "df = df.dropna(subset=['review_text'])\n",
    "\n",
    "print(df.shape)\n",
    "\n",
    "# 0 -- negative\n",
    "# 1 -- positive\n",
    "# 2 -- neutral\n",
    "df['rating'] = df['rating'].replace({1.0: 'negative', 2.0: 'negative'})\n",
    "df['rating'] = df['rating'].replace(3.0, 'negative')\n",
    "df['rating'] = df['rating'].replace({5.0: 'positive', 4.0: 'positive'})\n",
    "# df['rating'] = df['rating'].replace({1.0: 1, 2.0: 2})\n",
    "# df['rating'] = df['rating'].replace(3.0, 3)\n",
    "# df['rating'] = df['rating'].replace({5.0: 5, 4.0: 4})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = df['rating'].value_counts().sort_index().plot(kind='bar', title='Count of Reviews by Stars', figsize=(10, 5))\n",
    "ax.set_xlabel('Review Stars')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_text</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Like other reviewers i was hesitant to spend t...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>As is true of a bunch of the fall clothing pho...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I so wanted this skirt to work, love the desig...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Love love this! i was hesitant to buy this at ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I absolutely love the retro look of this swims...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         review_text    rating\n",
       "0  Like other reviewers i was hesitant to spend t...  positive\n",
       "1  As is true of a bunch of the fall clothing pho...  positive\n",
       "2  I so wanted this skirt to work, love the desig...  negative\n",
       "3  Love love this! i was hesitant to buy this at ...  positive\n",
       "4  I absolutely love the retro look of this swims...  positive"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I ordered these leggings and loved them, for about an hour- at which point the belt loop ripped off of the pant, leaving a hole. i called customer service and they sent me a 2nd pair. same thing happened. i never even pulled on the belt loop. they are just so flimsy. it's a shame bc they are cool looking.\n"
     ]
    }
   ],
   "source": [
    "before_preprocessing_example = df['review_text'][300]\n",
    "\n",
    "print(before_preprocessing_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/bohdan.mykhayliv/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# download the stopwords from NLTK\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re                                  # library for regular expression operations\n",
    "import string                              # for string operations\n",
    "\n",
    "from nltk.corpus import stopwords          # module for stop words that come with NLTK\n",
    "from nltk.stem import PorterStemmer        # module for stemming\n",
    "from nltk.tokenize import TweetTokenizer   # module for tokenizing strings\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     /Users/bohdan.mykhayliv/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(initial_text):\n",
    "  try:\n",
    "    text = re.sub(r'^RT[\\s]+', '', initial_text) \n",
    "    text = re.sub(r'https?:\\/\\/.*[\\r\\n]*', '', text)\n",
    "    text = re.sub(r'#', '', text)\n",
    "    tokenizer = TweetTokenizer(preserve_case=False, strip_handles=True, reduce_len=True)\n",
    "    text_tokens = tokenizer.tokenize(text)\n",
    "    stopwords_english = stopwords.words('english')\n",
    "    text_clean = []\n",
    "\n",
    "    for word in text_tokens:\n",
    "      # Remove stopwords and punctuation\n",
    "      if (word not in stopwords_english and word not in string.punctuation):\n",
    "          text_clean.append(word)\n",
    "\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    text_lem = [] \n",
    "\n",
    "    for word in text_clean:\n",
    "        try:\n",
    "          word = word.lower()\n",
    "        except:\n",
    "          continue\n",
    "\n",
    "        lem_word = lemmatizer.lemmatize(word)  # lemmatizing word\n",
    "        text_lem.append(lem_word) \n",
    "\n",
    "    return ' '.join(text_lem)\n",
    "  except:\n",
    "    return initial_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ordered legging loved hour point belt loop ripped pant leaving hole called customer service sent 2nd pair thing happened never even pulled belt loop flimsy shame bc cool looking\n"
     ]
    }
   ],
   "source": [
    "print(preprocess_text(before_preprocessing_example))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess all text in dataframe\n",
    "df['processed_review_text'] = df['review_text'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_text</th>\n",
       "      <th>rating</th>\n",
       "      <th>processed_review_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Like other reviewers i was hesitant to spend t...</td>\n",
       "      <td>positive</td>\n",
       "      <td>like reviewer hesitant spend much pair jean ho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>As is true of a bunch of the fall clothing pho...</td>\n",
       "      <td>positive</td>\n",
       "      <td>true bunch fall clothing photo color totally w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I so wanted this skirt to work, love the desig...</td>\n",
       "      <td>negative</td>\n",
       "      <td>wanted skirt work love design way way long ......</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Love love this! i was hesitant to buy this at ...</td>\n",
       "      <td>positive</td>\n",
       "      <td>love love hesitant buy first review made seem ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I absolutely love the retro look of this swims...</td>\n",
       "      <td>positive</td>\n",
       "      <td>absolutely love retro look swimsuit first saw ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         review_text    rating  \\\n",
       "0  Like other reviewers i was hesitant to spend t...  positive   \n",
       "1  As is true of a bunch of the fall clothing pho...  positive   \n",
       "2  I so wanted this skirt to work, love the desig...  negative   \n",
       "3  Love love this! i was hesitant to buy this at ...  positive   \n",
       "4  I absolutely love the retro look of this swims...  positive   \n",
       "\n",
       "                               processed_review_text  \n",
       "0  like reviewer hesitant spend much pair jean ho...  \n",
       "1  true bunch fall clothing photo color totally w...  \n",
       "2  wanted skirt work love design way way long ......  \n",
       "3  love love hesitant buy first review made seem ...  \n",
       "4  absolutely love retro look swimsuit first saw ...  "
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = list(df['processed_review_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'true bunch fall clothing photo color totally washed model image shame embroidery bright vivid totally unique bib area actually soft corduroy think nice transition fall winter term fit feel like maybe geared towards slender build slim cut found really flattering since sometimes swim tunic 5 7 128 small'"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['rating']\n",
    "\n",
    "# 0 -- negative\n",
    "# 1 -- positive\n",
    "# 2 -- neutral\n",
    "y = y.replace('negative', 0)\n",
    "y = y.replace('neutral', 2)\n",
    "y = y.replace('positive', 1)\n",
    "\n",
    "y = np.array(list(y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, ..., 1, 1, 1])"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data on train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing embedding layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_tokenizer = Tokenizer()\n",
    "# tokenizes the text data and creates a dictionary of word index mappings, where each word is assigned a unique integer ID.\n",
    "# This dictionary can then be used to convert a text sample into a sequence of integers, which can be fed into a deep learning model.\n",
    "word_tokenizer.fit_on_texts(X_train)\n",
    "\n",
    "# After fit_on_texts is called, the texts_to_sequences function can be used to convert each text sample into\n",
    "# a sequence of corresponding integers based on the dictionary created by fit_on_texts.\n",
    "# Transforms each text in texts to a sequence of integers.\n",
    "X_train = word_tokenizer.texts_to_sequences(X_train)\n",
    "X_test = word_tokenizer.texts_to_sequences(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_json = word_tokenizer.to_json()\n",
    "\n",
    "with open('./preparing/b3_tokenizer.json', 'w', encoding='utf-8') as f:\n",
    "    f.write(json.dumps(tokenizer_json, ensure_ascii=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11835"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Adding 1 to store dimensions for words for which no pretrained word embeddings exist\n",
    "vocab_length = len(word_tokenizer.word_index) + 1\n",
    "\n",
    "vocab_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxlen = 100\n",
    "\n",
    "X_train = pad_sequences(X_train, padding='post', maxlen=maxlen)\n",
    "X_test = pad_sequences(X_test, padding='post', maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import asarray\n",
    "from numpy import zeros\n",
    "\n",
    "embeddings_dictionary = dict()\n",
    "glove_file = open('./preparing/glove.6B.100d.txt', encoding=\"utf8\")\n",
    "\n",
    "for line in glove_file:\n",
    "    records = line.split()\n",
    "    word = records[0]\n",
    "    vector_dimensions = asarray(records[1:], dtype='float32')\n",
    "    embeddings_dictionary [word] = vector_dimensions\n",
    "glove_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Embedding Matrix having 100 columns \n",
    "# Containing 100-dimensional GloVe word embeddings for all words in our corpus.\n",
    "\n",
    "embedding_matrix = zeros((vocab_length, 100))\n",
    "for word, index in word_tokenizer.word_index.items():\n",
    "    embedding_vector = embeddings_dictionary.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[index] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11835, 100)"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training with:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "snn_model = Sequential()\n",
    "embedding_layer = Embedding(vocab_length, 100, weights=[embedding_matrix], input_length=maxlen , trainable=False)\n",
    "\n",
    "snn_model.add(embedding_layer)\n",
    "\n",
    "snn_model.add(Flatten())\n",
    "snn_model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_1 (Embedding)     (None, 100, 100)          1183500   \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 10000)             0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 10001     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,193,501\n",
      "Trainable params: 10,001\n",
      "Non-trainable params: 1,183,500\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "snn_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n",
    "\n",
    "print(snn_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n",
      "114/114 [==============================] - 1s 5ms/step - loss: 0.5072 - acc: 0.7667 - val_loss: 0.4662 - val_acc: 0.7844\n",
      "Epoch 2/6\n",
      "114/114 [==============================] - 0s 4ms/step - loss: 0.4251 - acc: 0.8031 - val_loss: 0.4486 - val_acc: 0.7900\n",
      "Epoch 3/6\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.3882 - acc: 0.8232 - val_loss: 0.4382 - val_acc: 0.7933\n",
      "Epoch 4/6\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.3651 - acc: 0.8389 - val_loss: 0.4358 - val_acc: 0.7999\n",
      "Epoch 5/6\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.3466 - acc: 0.8476 - val_loss: 0.4364 - val_acc: 0.8015\n",
      "Epoch 6/6\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.3343 - acc: 0.8538 - val_loss: 0.4395 - val_acc: 0.8043\n"
     ]
    }
   ],
   "source": [
    "snn_model_history = snn_model.fit(X_train, y_train, batch_size=128, epochs=6, verbose=1, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "142/142 [==============================] - 0s 1ms/step - loss: 0.4359 - acc: 0.8050\n"
     ]
    }
   ],
   "source": [
    "score = snn_model.evaluate(X_test, y_test, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Score: 0.43586039543151855\n",
      "Test Accuracy: 0.8050342202186584\n"
     ]
    }
   ],
   "source": [
    "print(\"Test Score:\", score[0])\n",
    "print(\"Test Accuracy:\", score[1])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Conv1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_model = Sequential()\n",
    "\n",
    "embedding_layer = Embedding(vocab_length, 100, weights=[embedding_matrix], input_length=maxlen , trainable=False)\n",
    "cnn_model.add(embedding_layer)\n",
    "\n",
    "cnn_model.add(Conv1D(filters=128, kernel_size=5, activation='relu'))\n",
    "\n",
    "cnn_model.add(GlobalMaxPooling1D())\n",
    "\n",
    "cnn_model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_9 (Embedding)     (None, 100, 100)          1183500   \n",
      "                                                                 \n",
      " conv1d_8 (Conv1D)           (None, 96, 128)           64128     \n",
      "                                                                 \n",
      " global_max_pooling1d_5 (Glo  (None, 128)              0         \n",
      " balMaxPooling1D)                                                \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,247,757\n",
      "Trainable params: 64,257\n",
      "Non-trainable params: 1,183,500\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "cnn_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n",
    "print(cnn_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "114/114 [==============================] - 4s 27ms/step - loss: 0.4974 - acc: 0.7793 - val_loss: 0.4003 - val_acc: 0.8126\n",
      "Epoch 2/10\n",
      "114/114 [==============================] - 3s 24ms/step - loss: 0.3483 - acc: 0.8507 - val_loss: 0.3677 - val_acc: 0.8253\n",
      "Epoch 3/10\n",
      "114/114 [==============================] - 3s 24ms/step - loss: 0.2933 - acc: 0.8803 - val_loss: 0.3409 - val_acc: 0.8482\n",
      "Epoch 4/10\n",
      "114/114 [==============================] - 3s 24ms/step - loss: 0.2549 - acc: 0.9000 - val_loss: 0.3348 - val_acc: 0.8507\n",
      "Epoch 5/10\n",
      "114/114 [==============================] - 3s 23ms/step - loss: 0.2168 - acc: 0.9215 - val_loss: 0.3692 - val_acc: 0.8385\n",
      "Epoch 6/10\n",
      "114/114 [==============================] - 3s 24ms/step - loss: 0.1834 - acc: 0.9384 - val_loss: 0.3266 - val_acc: 0.8562\n",
      "Epoch 7/10\n",
      "114/114 [==============================] - 3s 24ms/step - loss: 0.1512 - acc: 0.9554 - val_loss: 0.3370 - val_acc: 0.8540\n",
      "Epoch 8/10\n",
      "114/114 [==============================] - 3s 23ms/step - loss: 0.1264 - acc: 0.9674 - val_loss: 0.3326 - val_acc: 0.8548\n",
      "Epoch 9/10\n",
      "114/114 [==============================] - 3s 23ms/step - loss: 0.1012 - acc: 0.9801 - val_loss: 0.3515 - val_acc: 0.8526\n",
      "Epoch 10/10\n",
      "114/114 [==============================] - 3s 25ms/step - loss: 0.0792 - acc: 0.9902 - val_loss: 0.3563 - val_acc: 0.8498\n"
     ]
    }
   ],
   "source": [
    "cnn_model_history = cnn_model.fit(X_train, y_train, batch_size=128, epochs=10, verbose=1, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "142/142 [==============================] - 1s 4ms/step - loss: 0.3486 - acc: 0.8616\n"
     ]
    }
   ],
   "source": [
    "cnn_model_score = cnn_model.evaluate(X_test, y_test, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Score: 0.34857526421546936\n",
      "Test Accuracy: 0.8615588545799255\n"
     ]
    }
   ],
   "source": [
    "print(\"Test Score:\", cnn_model_score[0])\n",
    "print(\"Test Accuracy:\", cnn_model_score[1])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recurrent Neural Network (LSTM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-25 21:00:11.673865: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-05-25 21:00:11.675463: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-05-25 21:00:11.676774: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    }
   ],
   "source": [
    "lstm_model = Sequential()\n",
    "embedding_layer = Embedding(vocab_length, 100, weights=[embedding_matrix], input_length=maxlen , trainable=False)\n",
    "\n",
    "lstm_model.add(embedding_layer)\n",
    "lstm_model.add(LSTM(128))\n",
    "\n",
    "lstm_model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_7 (Embedding)     (None, 100, 100)          1183500   \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 128)               117248    \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,300,877\n",
      "Trainable params: 117,377\n",
      "Non-trainable params: 1,183,500\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "lstm_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n",
    "print(lstm_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-25 00:31:01.817826: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-05-25 00:31:01.819220: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-05-25 00:31:01.820741: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-05-25 00:31:02.530993: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-05-25 00:31:02.532966: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-05-25 00:31:02.534282: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114/114 [==============================] - ETA: 0s - loss: 0.5497 - acc: 0.7707"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-25 00:31:35.914947: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-05-25 00:31:35.917547: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-05-25 00:31:35.919770: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114/114 [==============================] - 38s 320ms/step - loss: 0.5497 - acc: 0.7707 - val_loss: 0.5449 - val_acc: 0.7662\n",
      "Epoch 2/6\n",
      "114/114 [==============================] - 46s 403ms/step - loss: 0.5379 - acc: 0.7707 - val_loss: 0.5465 - val_acc: 0.7662\n",
      "Epoch 3/6\n",
      "114/114 [==============================] - 46s 407ms/step - loss: 0.5362 - acc: 0.7713 - val_loss: 0.5413 - val_acc: 0.7662\n",
      "Epoch 4/6\n",
      "114/114 [==============================] - 41s 362ms/step - loss: 0.5289 - acc: 0.7713 - val_loss: 0.4962 - val_acc: 0.7659\n",
      "Epoch 5/6\n",
      "114/114 [==============================] - 48s 418ms/step - loss: 0.5013 - acc: 0.7716 - val_loss: 0.4599 - val_acc: 0.7657\n",
      "Epoch 6/6\n",
      "114/114 [==============================] - 46s 409ms/step - loss: 0.4683 - acc: 0.7800 - val_loss: 0.4503 - val_acc: 0.7720\n"
     ]
    }
   ],
   "source": [
    "lstm_model_history = lstm_model.fit(X_train, y_train, batch_size=128, epochs=6, verbose=1, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "142/142 [==============================] - 28s 196ms/step - loss: 0.4561 - acc: 0.7662\n"
     ]
    }
   ],
   "source": [
    "lstm_model_score = lstm_model.evaluate(X_test, y_test, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Score: 0.45611825585365295\n",
      "Test Accuracy: 0.7661735415458679\n"
     ]
    }
   ],
   "source": [
    "print(\"Test Score:\", lstm_model_score[0])\n",
    "print(\"Test Accuracy:\", lstm_model_score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_model.save(f\"./models/c1_lstm_model_acc_{round(lstm_model_score[1], 3)}.h5\", save_format='h5')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/bohdan.mykhayliv/Documents/ucu/year3_semester2/ml/project/programming'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_1 (Embedding)     (None, 100, 100)          1346000   \n",
      "                                                                 \n",
      " conv1d (Conv1D)             (None, 96, 128)           64128     \n",
      "                                                                 \n",
      " global_max_pooling1d (Globa  (None, 128)              0         \n",
      " lMaxPooling1D)                                                  \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,410,257\n",
      "Trainable params: 64,257\n",
      "Non-trainable params: 1,346,000\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "model_path ='./models/c1_cnn_model_acc_0.868.h5'\n",
    "pretrained_model = load_model(model_path)\n",
    "\n",
    "pretrained_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_review = 'I absolutely love this dress! The fabric is incredibly soft and comfortable, and the fit is perfect for my body type. The color is vibrant and has not faded at all after multiple washes. The design is unique and eye-catching, and I have received numerous compliments every time I wear it. The attention to detail is also impressive, with intricate stitching and a flattering silhouette. Overall, I would highly recommend this dress to anyone looking for a high-quality, stylish addition to their wardrobe.'\n",
    "neutral_review = 'I recently purchased this dress and thought it was decent. The fabric was of average quality and the fit was mostly true to size, although I did have to make a few minor alterations to get it to fit just right. The color was nice, but not quite as vibrant as I was expecting. The design was simple and understated, which could be either a positive or negative depending on personal style preferences. Overall, I would say this dress is a solid option for a more casual or everyday look.'\n",
    "negative_review = ' was really disappointed with this dress. The fabric felt cheap and scratchy against my skin, and the fit was all wrong. The dress was advertised as being true to size, but it was way too tight in some areas and too loose in others. The color also looked different in person than it did online, and I was not a fan of how it looked on me. Additionally, the seams were poorly done and started coming apart after just a few wears. Overall, I would not recommend this dress to anyone.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_positive_review = preprocess_text(positive_review)\n",
    "preprocessed_neutral_review = preprocess_text(neutral_review)\n",
    "preprocessed_negative_review = preprocess_text(negative_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_preprocessing.text import tokenizer_from_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./preparing/b3_tokenizer.json') as f:\n",
    "    data = json.load(f)\n",
    "    loaded_tokenizer = tokenizer_from_json(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_list = [preprocessed_positive_review, preprocessed_neutral_review, preprocessed_negative_review]\n",
    "\n",
    "reviews_tokenized = loaded_tokenizer.texts_to_sequences(reviews_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[2,\n",
       "  257,\n",
       "  21,\n",
       "  7,\n",
       "  18,\n",
       "  1,\n",
       "  45,\n",
       "  6,\n",
       "  664,\n",
       "  60,\n",
       "  3,\n",
       "  70,\n",
       "  3,\n",
       "  1,\n",
       "  27,\n",
       "  6,\n",
       "  54,\n",
       "  12,\n",
       "  17,\n",
       "  175,\n",
       "  462,\n",
       "  1,\n",
       "  47,\n",
       "  6,\n",
       "  511,\n",
       "  3,\n",
       "  89,\n",
       "  19,\n",
       "  1344,\n",
       "  44,\n",
       "  74,\n",
       "  201,\n",
       "  1132,\n",
       "  1154,\n",
       "  1,\n",
       "  143,\n",
       "  6,\n",
       "  279,\n",
       "  3,\n",
       "  659,\n",
       "  1715,\n",
       "  3,\n",
       "  2,\n",
       "  24,\n",
       "  240,\n",
       "  2120,\n",
       "  214,\n",
       "  320,\n",
       "  188,\n",
       "  2,\n",
       "  32,\n",
       "  5,\n",
       "  1,\n",
       "  1110,\n",
       "  8,\n",
       "  256,\n",
       "  6,\n",
       "  87,\n",
       "  3757,\n",
       "  14,\n",
       "  1862,\n",
       "  797,\n",
       "  3,\n",
       "  4,\n",
       "  58,\n",
       "  931,\n",
       "  255,\n",
       "  2,\n",
       "  41,\n",
       "  437,\n",
       "  210,\n",
       "  7,\n",
       "  18,\n",
       "  8,\n",
       "  849,\n",
       "  183,\n",
       "  12,\n",
       "  4,\n",
       "  179,\n",
       "  96,\n",
       "  519,\n",
       "  674,\n",
       "  8,\n",
       "  565,\n",
       "  480],\n",
       " [2,\n",
       "  943,\n",
       "  140,\n",
       "  7,\n",
       "  18,\n",
       "  3,\n",
       "  195,\n",
       "  5,\n",
       "  15,\n",
       "  1755,\n",
       "  1,\n",
       "  45,\n",
       "  15,\n",
       "  13,\n",
       "  900,\n",
       "  96,\n",
       "  3,\n",
       "  1,\n",
       "  27,\n",
       "  15,\n",
       "  1105,\n",
       "  131,\n",
       "  8,\n",
       "  22,\n",
       "  436,\n",
       "  2,\n",
       "  133,\n",
       "  24,\n",
       "  8,\n",
       "  189,\n",
       "  4,\n",
       "  378,\n",
       "  2015,\n",
       "  2247,\n",
       "  8,\n",
       "  115,\n",
       "  5,\n",
       "  8,\n",
       "  27,\n",
       "  39,\n",
       "  126,\n",
       "  1,\n",
       "  47,\n",
       "  15,\n",
       "  69,\n",
       "  10,\n",
       "  19,\n",
       "  262,\n",
       "  31,\n",
       "  511,\n",
       "  31,\n",
       "  2,\n",
       "  15,\n",
       "  785,\n",
       "  1,\n",
       "  143,\n",
       "  15,\n",
       "  561,\n",
       "  3,\n",
       "  2052,\n",
       "  82,\n",
       "  119,\n",
       "  29,\n",
       "  438,\n",
       "  4,\n",
       "  1487,\n",
       "  37,\n",
       "  1184,\n",
       "  702,\n",
       "  11,\n",
       "  1763,\n",
       "  132,\n",
       "  255,\n",
       "  2,\n",
       "  41,\n",
       "  277,\n",
       "  7,\n",
       "  18,\n",
       "  6,\n",
       "  4,\n",
       "  909,\n",
       "  946,\n",
       "  12,\n",
       "  4,\n",
       "  50,\n",
       "  198,\n",
       "  37,\n",
       "  984,\n",
       "  48],\n",
       " [15,\n",
       "  51,\n",
       "  327,\n",
       "  14,\n",
       "  7,\n",
       "  18,\n",
       "  1,\n",
       "  45,\n",
       "  266,\n",
       "  487,\n",
       "  3,\n",
       "  860,\n",
       "  1052,\n",
       "  17,\n",
       "  502,\n",
       "  3,\n",
       "  1,\n",
       "  27,\n",
       "  15,\n",
       "  74,\n",
       "  682,\n",
       "  1,\n",
       "  18,\n",
       "  15,\n",
       "  2790,\n",
       "  31,\n",
       "  208,\n",
       "  131,\n",
       "  8,\n",
       "  22,\n",
       "  10,\n",
       "  5,\n",
       "  15,\n",
       "  114,\n",
       "  35,\n",
       "  150,\n",
       "  9,\n",
       "  152,\n",
       "  1089,\n",
       "  3,\n",
       "  35,\n",
       "  172,\n",
       "  9,\n",
       "  525,\n",
       "  1,\n",
       "  47,\n",
       "  87,\n",
       "  158,\n",
       "  239,\n",
       "  9,\n",
       "  164,\n",
       "  71,\n",
       "  5,\n",
       "  133,\n",
       "  135,\n",
       "  3,\n",
       "  2,\n",
       "  15,\n",
       "  19,\n",
       "  4,\n",
       "  770,\n",
       "  13,\n",
       "  166,\n",
       "  5,\n",
       "  158,\n",
       "  11,\n",
       "  30,\n",
       "  2658,\n",
       "  1,\n",
       "  777,\n",
       "  127,\n",
       "  1539,\n",
       "  859,\n",
       "  3,\n",
       "  1393,\n",
       "  1005,\n",
       "  1176,\n",
       "  201,\n",
       "  39,\n",
       "  4,\n",
       "  378,\n",
       "  1059,\n",
       "  255,\n",
       "  2,\n",
       "  41,\n",
       "  19,\n",
       "  210,\n",
       "  7,\n",
       "  18,\n",
       "  8,\n",
       "  849]]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_padded = pad_sequences(reviews_tokenized, padding='post', maxlen=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   2,  257,   21,    7,   18,    1,   45,    6,  664,   60,    3,\n",
       "          70,    3,    1,   27,    6,   54,   12,   17,  175,  462,    1,\n",
       "          47,    6,  511,    3,   89,   19, 1344,   44,   74,  201, 1132,\n",
       "        1154,    1,  143,    6,  279,    3,  659, 1715,    3,    2,   24,\n",
       "         240, 2120,  214,  320,  188,    2,   32,    5,    1, 1110,    8,\n",
       "         256,    6,   87, 3757,   14, 1862,  797,    3,    4,   58,  931,\n",
       "         255,    2,   41,  437,  210,    7,   18,    8,  849,  183,   12,\n",
       "           4,  179,   96,  519,  674,    8,  565,  480,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0],\n",
       "       [   2,  943,  140,    7,   18,    3,  195,    5,   15, 1755,    1,\n",
       "          45,   15,   13,  900,   96,    3,    1,   27,   15, 1105,  131,\n",
       "           8,   22,  436,    2,  133,   24,    8,  189,    4,  378, 2015,\n",
       "        2247,    8,  115,    5,    8,   27,   39,  126,    1,   47,   15,\n",
       "          69,   10,   19,  262,   31,  511,   31,    2,   15,  785,    1,\n",
       "         143,   15,  561,    3, 2052,   82,  119,   29,  438,    4, 1487,\n",
       "          37, 1184,  702,   11, 1763,  132,  255,    2,   41,  277,    7,\n",
       "          18,    6,    4,  909,  946,   12,    4,   50,  198,   37,  984,\n",
       "          48,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0],\n",
       "       [  15,   51,  327,   14,    7,   18,    1,   45,  266,  487,    3,\n",
       "         860, 1052,   17,  502,    3,    1,   27,   15,   74,  682,    1,\n",
       "          18,   15, 2790,   31,  208,  131,    8,   22,   10,    5,   15,\n",
       "         114,   35,  150,    9,  152, 1089,    3,   35,  172,    9,  525,\n",
       "           1,   47,   87,  158,  239,    9,  164,   71,    5,  133,  135,\n",
       "           3,    2,   15,   19,    4,  770,   13,  166,    5,  158,   11,\n",
       "          30, 2658,    1,  777,  127, 1539,  859,    3, 1393, 1005, 1176,\n",
       "         201,   39,    4,  378, 1059,  255,    2,   41,   19,  210,    7,\n",
       "          18,    8,  849,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0]], dtype=int32)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 66ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.9418644 ],\n",
       "       [0.18463959],\n",
       "       [0.00126234]], dtype=float32)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Passing tokenised instance to the LSTM model for predictions\n",
    "reviews_sentiments = pretrained_model.predict(reviews_padded)\n",
    "\n",
    "reviews_sentiments"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting Aspects:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word(ann, sentenceIndex, tokenIndex):\n",
    "    return ann.sentence[sentenceIndex].token[tokenIndex].word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "def join_compounds(ann):\n",
    "    compound_main_words = dict()\n",
    "    num_of_sentences = len(ann.sentence)\n",
    "    for sentenceIndex in range(num_of_sentences):\n",
    "        compound_ties = dict()\n",
    "        compound_headIndexes = []\n",
    "        sentence = ann.sentence[sentenceIndex]\n",
    "        for dependencie in sentence.basicDependencies.edge:\n",
    "            if dependencie.dep == 'compound':\n",
    "                ### if we already had that gov word\n",
    "                if dependencie.source in compound_ties:\n",
    "                    if (abs(dependencie.source - dependencie.target) < abs(dependencie.source - compound_ties[dependencie.source])):\n",
    "                        compound_headIndexes.remove(compound_ties[dependencie.source])\n",
    "                        compound_ties[dependencie.source] = dependencie.target\n",
    "                        compound_headIndexes.append(dependencie.target)\n",
    "                    continue\n",
    "                # print(dependencie.source, dependencie.target)\n",
    "                compound_ties[dependencie.source] = dependencie.target\n",
    "                compound_headIndexes.append(dependencie.target)\n",
    "                compound_headIndexes.append(dependencie.source)\n",
    "\n",
    "        compound_headIndexes.sort()\n",
    "        compound_chain = False\n",
    "        # print(compound_ties)\n",
    "        # print([(headIndex, get_word(ann, sentenceIndex, headIndex-1)) for headIndex in compound_headIndexes])\n",
    "        while True:\n",
    "            if len(compound_headIndexes) == 0:\n",
    "                break\n",
    "            if compound_chain == False:\n",
    "                compound_headIndex = max(compound_headIndexes)\n",
    "                main_compound_index = compound_headIndex\n",
    "                compound_main_words[(sentenceIndex, main_compound_index)] = [get_word(ann, sentenceIndex, main_compound_index-1)]\n",
    "                compound_headIndexes.remove(compound_headIndex)\n",
    "                compound_chain = True\n",
    "            else:\n",
    "                if compound_headIndex in compound_ties:\n",
    "                    compound_headIndex = compound_ties[compound_headIndex]\n",
    "                    compound_headIndexes.remove(compound_headIndex)\n",
    "                    compound_main_words[(sentenceIndex, main_compound_index)].append(get_word(ann, sentenceIndex, compound_headIndex-1))\n",
    "                else:\n",
    "                    compound_chain = False\n",
    "\n",
    "\n",
    "    final_compounds = dict()\n",
    "    for main_compound_key in compound_main_words:\n",
    "        reversed_words = compound_main_words[main_compound_key]\n",
    "        n = len(reversed_words)\n",
    "        words = [0]*n\n",
    "        for i in range(n):\n",
    "            words[i] = reversed_words[n-i-1]\n",
    "        final_compounds[main_compound_key] = \"-\".join(words)\n",
    "\n",
    "    return final_compounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "def join_xcomp_advmod(ann):\n",
    "    advmods = dict()\n",
    "    xcomps = dict()\n",
    "    num_of_sentences = len(ann.sentence)\n",
    "    for sentenceIndex in range(num_of_sentences):\n",
    "        sentence = ann.sentence[sentenceIndex]\n",
    "        for dependencie in sentence.basicDependencies.edge:\n",
    "            if dependencie.dep == 'advmod':\n",
    "                if not (get_word(ann, sentenceIndex, dependencie.target-1) == \"WRB\"):\n",
    "                    advmods[(sentenceIndex, dependencie.source)] = (sentenceIndex, dependencie.target)\n",
    "            if dependencie.dep == 'xcomp':\n",
    "                xcomps[(sentenceIndex, dependencie.source)] = (sentenceIndex, dependencie.target)\n",
    "\n",
    "    xcomps_advmods = dict()\n",
    "    for gov in advmods:\n",
    "        dependent = advmods[gov]\n",
    "        gov_word = get_word(ann, gov[0], gov[1]-1)\n",
    "        dep_word = get_word(ann, dependent[0], dependent[1]-1)\n",
    "        if dependent[1] > gov[1]:\n",
    "            xcomps_advmods[gov] = f\"{gov_word}-{dep_word}\"\n",
    "        else:\n",
    "            xcomps_advmods[gov] = f\"{dep_word}-{gov_word}\"\n",
    "\n",
    "    for gov in xcomps:\n",
    "        dependent = xcomps[gov]\n",
    "        gov_word = get_word(ann, gov[0], gov[1]-1)\n",
    "        dependent_word = get_word(ann, dependent[0], dependent[1]-1)\n",
    "        if dependent in xcomps_advmods:\n",
    "            dependent_word = xcomps_advmods[dependent]\n",
    "\n",
    "        xcomps_advmods[gov] = f\"{gov_word}-{dependent_word}\"\n",
    "\n",
    "    return xcomps_advmods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_with_corefs(ann, opinion_pairs, corefs_pivot):\n",
    "    n = len(opinion_pairs)\n",
    "    for i in range(n):\n",
    "        opinion_pair = opinion_pairs[i]\n",
    "        dependencie_type = opinion_pair[0]\n",
    "        new_governor = opinion_pair[1]\n",
    "        new_dependent = opinion_pair[2]\n",
    "        if opinion_pair[1][1] in corefs_pivot:\n",
    "            new_governor_ind = corefs_pivot[opinion_pair[1][1]]\n",
    "            new_governor = (ann.sentence[new_governor_ind[0]].token[new_governor_ind[1] - 1].word, new_governor_ind)\n",
    "\n",
    "        if opinion_pair[2][1] in corefs_pivot:\n",
    "            new_dependent_ind = corefs_pivot[opinion_pair[2][1]]\n",
    "            new_dependent = (ann.sentence[new_dependent_ind[0]].token[new_dependent_ind[1] - 1].word, new_dependent_ind)\n",
    "\n",
    "        opinion_pairs[i] = (dependencie_type,new_governor, new_dependent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_words_with_structure(opinion_pairs, structure_dict):\n",
    "    n = len(opinion_pairs)\n",
    "    for i in range(n):\n",
    "        opinion_pair = opinion_pairs[i]\n",
    "        dependencie_type = opinion_pair[0]\n",
    "        new_governor = opinion_pair[1]\n",
    "        new_dependent = opinion_pair[2]\n",
    "        if opinion_pair[1][1] in structure_dict:\n",
    "            new_governor_word = structure_dict[opinion_pair[1][1]]\n",
    "            new_governor = (new_governor_word, opinion_pair[1][1])\n",
    "\n",
    "        if opinion_pair[2][1] in structure_dict:\n",
    "            new_dependent_word = structure_dict[opinion_pair[2][1]]\n",
    "            new_dependent = (new_dependent_word, opinion_pair[2][1])\n",
    "\n",
    "        opinion_pairs[i] = (dependencie_type ,new_governor, new_dependent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "def substract_opinion_pairs(ann, dependencies, unresolved_mentions):\n",
    "    opinion_pairs = []\n",
    "    for dependencie in dependencies:\n",
    "        if ((dependencie[0] == 'nsubj') and (dependencie[2][1] not in unresolved_mentions) and (ann.sentence[dependencie[1][1][0]].token[dependencie[1][1][1]-1].sentiment != \"Neutral\")):\n",
    "            opinion_pairs.append(dependencie)\n",
    "        elif ((dependencie[0] == 'amod') and (ann.sentence[dependencie[1][1][0]].token[dependencie[2][1][1]-1].pos == \"JJ\")):\n",
    "            opinion_pairs.append(dependencie)\n",
    "        elif ((dependencie[0] == 'obj') and (ann.sentence[dependencie[1][1][0]].token[dependencie[1][1][1]-1].sentiment != \"Neutral\")):   ### ??????\n",
    "            opinion_pairs.append(dependencie)\n",
    "        else:\n",
    "            continue\n",
    "    return opinion_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_dependencies(ann):\n",
    "    dependencies = []\n",
    "    num_of_sentences = len(ann.sentence)\n",
    "    for sentenceIndex in range(num_of_sentences):\n",
    "        sentence = ann.sentence[sentenceIndex]\n",
    "        for dependencie in sentence.basicDependencies.edge:\n",
    "            governor = (sentenceIndex, dependencie.source)\n",
    "            relation_type = dependencie.dep\n",
    "            dependent = (sentenceIndex, dependencie.target)\n",
    "            # One dependencie: ('obj', ('enjoyed', (0, 2)), ('resolution', (0, 5)))\n",
    "            dependencies.append((relation_type, (sentence.token[governor[1]-1].word, governor), (sentence.token[dependent[1]-1].word, dependent)))\n",
    "    return dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_aspects_dict(opinion_pairs):\n",
    "    aspects_dict = dict()    # {aspect: [sentiment_word1, ....]}\n",
    "    for opinion_pair in opinion_pairs:\n",
    "        aspect = opinion_pair[2]\n",
    "        sentiment_word = opinion_pair[1]\n",
    "        if (opinion_pair[0] == 'nsubj'):\n",
    "            aspect = opinion_pair[2]\n",
    "            sentiment_word = opinion_pair[1]\n",
    "        elif (opinion_pair[0] == 'amod'):\n",
    "            aspect = opinion_pair[1]\n",
    "            sentiment_word = opinion_pair[2]\n",
    "        elif (opinion_pair[0] == 'obj'):\n",
    "            aspect = opinion_pair[2]\n",
    "            sentiment_word = opinion_pair[1]\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "        if aspect in aspects_dict:\n",
    "            aspects_dict[aspect].append(sentiment_word)\n",
    "        else:\n",
    "            aspects_dict[aspect] = [sentiment_word]\n",
    "\n",
    "    return aspects_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_apects_dict(aspects_dict):\n",
    "    for aspect in aspects_dict:\n",
    "        print(aspect[0], ': ', [sentiment_word[0] for sentiment_word in aspects_dict[aspect]], sep='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_text(text):\n",
    "    ann = None\n",
    "    # Set up the client\n",
    "    with CoreNLPClient(be_quite=False, annotators=['tokenize', 'ssplit', 'pos', 'lemma', 'ner', 'parse', 'coref'], timeout=30000, memory='16G', endpoint='http://localhost:5003') as client:        \n",
    "        # Parse the text using the client\n",
    "        ann = client.annotate(text)\n",
    "\n",
    "        client.stop()\n",
    "    return ann\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_corefs(ann):\n",
    "    corefs = {}\n",
    "    unresolved_mentions = set()\n",
    "    min_indexes = set()\n",
    "    for coref in ann.corefChain:\n",
    "        mentions = []\n",
    "        min_sentenceIndex = float(\"inf\")\n",
    "        min_headIndex = float(\"inf\")\n",
    "        for mention in coref.mention:\n",
    "            if mention.sentenceIndex == min_sentenceIndex:\n",
    "                if mention.headIndex < min_headIndex:\n",
    "                    min_headIndex = mention.headIndex\n",
    "            if mention.sentenceIndex < min_sentenceIndex:\n",
    "                min_sentenceIndex = mention.sentenceIndex\n",
    "                min_headIndex = mention.headIndex\n",
    "\n",
    "            mentions.append((mention.sentenceIndex, mention.headIndex + 1))\n",
    "        min_indexes.add((min_sentenceIndex, min_headIndex + 1))\n",
    "        if len(mentions) > 1:\n",
    "            for mention in mentions:\n",
    "                key = mention[0], mention[1]\n",
    "                value = [m for m in mentions if m != mention]\n",
    "                corefs[key] = value\n",
    "        else:\n",
    "            if len(mentions) == 1:\n",
    "                ### add pronouns to unresolved\n",
    "                if ann.sentence[mentions[0][0]].token[mentions[0][1]-1].pos == \"PRP\":\n",
    "                    unresolved_mentions.add(mentions[0])\n",
    "\n",
    "    corefs_pivot = {}\n",
    "    for key in corefs:\n",
    "        if key in min_indexes:\n",
    "            replacable_words = corefs[key]\n",
    "            ### add pronouns to unresolved\n",
    "            if ann.sentence[key[0]].token[key[1]-1].pos == \"PRP\":\n",
    "                unresolved_mentions.add(key)\n",
    "                for replacable_word in replacable_words:\n",
    "                    unresolved_mentions.add(replacable_word)\n",
    "            ##############################\n",
    "            for replacable_word in replacable_words:\n",
    "                corefs_pivot[replacable_word] = key\n",
    "\n",
    "    return corefs_pivot, unresolved_mentions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-25 01:07:13 INFO: Writing properties to tmp file: corenlp_server-f2a19d89e9214726.props\n",
      "2023-05-25 01:07:13 INFO: Starting server with command: java -Xmx16G -cp ./stanford-corenlp-4.5.4/* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 5003 -timeout 30000 -threads 5 -maxCharLength 100000 -quiet False -serverProperties corenlp_server-f2a19d89e9214726.props -annotators tokenize,ssplit,pos,lemma,ner,parse,coref -preload -outputFormat serialized\n",
      "[main] INFO CoreNLP - --- StanfordCoreNLPServer#main() called ---\n",
      "[main] INFO CoreNLP - Server default properties:\n",
      "\t\t\t(Note: unspecified annotator properties are English defaults)\n",
      "\t\t\tannotators = tokenize,ssplit,pos,lemma,ner,parse,coref\n",
      "\t\t\tinputFormat = text\n",
      "\t\t\toutputFormat = serialized\n",
      "\t\t\tprettyPrint = false\n",
      "\t\t\tthreads = 5\n",
      "[main] INFO CoreNLP - Threads: 5\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator pos\n",
      "[main] INFO edu.stanford.nlp.tagger.maxent.MaxentTagger - Loading POS tagger from edu/stanford/nlp/models/pos-tagger/english-left3words-distsim.tagger ... done [0.5 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "[main] INFO edu.stanford.nlp.ie.AbstractSequenceClassifier - Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.0 sec].\n",
      "[main] INFO edu.stanford.nlp.ie.AbstractSequenceClassifier - Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "[main] INFO edu.stanford.nlp.ie.AbstractSequenceClassifier - Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.7 sec].\n",
      "[main] INFO edu.stanford.nlp.time.JollyDayHolidays - Initializing JollyDayHoliday for SUTime from classpath edu/stanford/nlp/models/sutime/jollyday/Holidays_sutime.xml as sutime.binder.1.\n",
      "[main] INFO edu.stanford.nlp.time.TimeExpressionExtractorImpl - Using following SUTime rules: edu/stanford/nlp/models/sutime/defs.sutime.txt,edu/stanford/nlp/models/sutime/english.sutime.txt,edu/stanford/nlp/models/sutime/english.holidays.sutime.txt\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokensRegexNERAnnotator - ner.fine.regexner: Read 580705 unique entries out of 581864 from edu/stanford/nlp/models/kbp/english/gazetteers/regexner_caseless.tab, 0 TokensRegex patterns.\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokensRegexNERAnnotator - ner.fine.regexner: Read 4867 unique entries out of 4867 from edu/stanford/nlp/models/kbp/english/gazetteers/regexner_cased.tab, 0 TokensRegex patterns.\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokensRegexNERAnnotator - ner.fine.regexner: Read 585572 unique entries from 2 files\n",
      "[main] INFO edu.stanford.nlp.pipeline.NERCombinerAnnotator - numeric classifiers: true; SUTime: true [no docDate]; fine grained: true\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... done [0.5 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator coref\n",
      "[main] INFO edu.stanford.nlp.coref.statistical.SimpleLinearClassifier - Loading coref model edu/stanford/nlp/models/coref/statistical/ranking_model.ser.gz ... done [0.6 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.CorefMentionAnnotator - Using mention detector type: dependency\n",
      "[main] INFO CoreNLP - Starting server...\n",
      "[main] INFO CoreNLP - StanfordCoreNLPServer listening at /0.0.0.0:5003\n",
      "[pool-1-thread-3] INFO CoreNLP - [/127.0.0.1:62793] API call w/annotators tokenize,pos,lemma,ner,parse,coref\n",
      "[pool-1-thread-3] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[pool-1-thread-3] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator pos\n",
      "[pool-1-thread-3] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[pool-1-thread-3] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "[pool-1-thread-3] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[pool-1-thread-3] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator coref\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I enjoyed the body fit, it is very good for such a cheap dress. Also, I liked the fabrik, because it feels so soft!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Thread-0] INFO CoreNLP - CoreNLP Server is shutting down.\n"
     ]
    }
   ],
   "source": [
    "text = \"I enjoyed the body fit, it is very good for such a cheap dress. Also, I liked the fabrik, because it feels so soft!\"\n",
    "ann = parse_text(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opinion pairs:\n",
      "('obj', ('enjoyed', (0, 2)), ('fit', (0, 5)))\n",
      "('nsubj', ('good', (0, 10)), ('it', (0, 7)))\n",
      "('amod', ('dress', (0, 15)), ('cheap', (0, 14)))\n",
      "('obj', ('liked', (1, 4)), ('fabrik', (1, 6)))\n",
      "('nsubj', ('feels', (1, 10)), ('it', (1, 9)))\n",
      "Opinion pairs after coreference:\n",
      "('obj', ('enjoyed', (0, 2)), ('fit', (0, 5)))\n",
      "('nsubj', ('good', (0, 10)), ('it', (0, 7)))\n",
      "('amod', ('dress', (0, 15)), ('cheap', (0, 14)))\n",
      "('obj', ('liked', (1, 4)), ('fabrik', (1, 6)))\n",
      "('nsubj', ('feels', (1, 10)), ('fabrik', (1, 6)))\n",
      "Opinion pairs after connecting compounds:\n",
      "('obj', ('enjoyed', (0, 2)), ('body-fit', (0, 5)))\n",
      "('nsubj', ('good', (0, 10)), ('it', (0, 7)))\n",
      "('amod', ('dress', (0, 15)), ('cheap', (0, 14)))\n",
      "('obj', ('liked', (1, 4)), ('fabrik', (1, 6)))\n",
      "('nsubj', ('feels', (1, 10)), ('fabrik', (1, 6)))\n",
      "Opinion pairs after connecting xcomps and advmods:\n",
      "('obj', ('enjoyed', (0, 2)), ('body-fit', (0, 5)))\n",
      "('nsubj', ('very-good', (0, 10)), ('it', (0, 7)))\n",
      "('amod', ('dress', (0, 15)), ('cheap', (0, 14)))\n",
      "('obj', ('Also-liked', (1, 4)), ('fabrik', (1, 6)))\n",
      "('nsubj', ('feels-so-soft', (1, 10)), ('fabrik', (1, 6)))\n",
      "Aspects dict:\n",
      "body-fit: ['enjoyed']\n",
      "it: ['very-good']\n",
      "dress: ['cheap']\n",
      "fabrik: ['Also-liked', 'feels-so-soft']\n"
     ]
    }
   ],
   "source": [
    "compounds = join_compounds(ann)\n",
    "xcomps_advmods = join_xcomp_advmod(ann)\n",
    "\n",
    "# Extract the set of grammar dependencies\n",
    "# One dependencie: ('obj', ('enjoyed', (0, 2)), ('resolution', (0, 5)))\n",
    "dependencies = extract_dependencies(ann)\n",
    "\n",
    "corefs_pivot, unresolved_mentions = get_corefs(ann)\n",
    "# One opinion pair: ('obj', ('enjoyed', (0, 2)), ('resolution', (0, 5)))\n",
    "opinion_pairs = substract_opinion_pairs(ann, dependencies, unresolved_mentions)\n",
    "\n",
    "print(\"Opinion pairs:\")\n",
    "for opinion_pair in opinion_pairs:\n",
    "    print(opinion_pair)\n",
    "\n",
    "# Replace words with their coreferences\n",
    "replace_with_corefs(ann, opinion_pairs, corefs_pivot)\n",
    "\n",
    "print(\"Opinion pairs after coreference:\")\n",
    "for opinion_pair in opinion_pairs:\n",
    "    print(opinion_pair)\n",
    "\n",
    "# Connecting compounds\n",
    "replace_words_with_structure(opinion_pairs, compounds)\n",
    "\n",
    "print(\"Opinion pairs after connecting compounds:\")\n",
    "for opinion_pair in opinion_pairs:\n",
    "    print(opinion_pair)\n",
    "\n",
    "# Connecting xcomps and advmods\n",
    "replace_words_with_structure(opinion_pairs, xcomps_advmods)\n",
    "print(\"Opinion pairs after connecting xcomps and advmods:\")\n",
    "for opinion_pair in opinion_pairs:\n",
    "    print(opinion_pair)\n",
    "\n",
    "aspects_dict = create_aspects_dict(opinion_pairs)\n",
    "print(\"Aspects dict:\")\n",
    "print_apects_dict(aspects_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
